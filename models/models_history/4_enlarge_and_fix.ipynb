{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.io import imshow\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 948953259486936212\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11285227111\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1978273379820467455\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#making sure GPU is in use \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "in_height = 64\n",
    "in_width = 64\n",
    "out_height = 256\n",
    "out_width = 256\n",
    "color_dim = 3\n",
    "path_in = '/home/Matthew/image-super-resolution/data/imagenet/10k/res64/'\n",
    "path_out = '/home/Matthew/image-super-resolution/data/imagenet/10k/res256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo: add random shuffle \n",
    "#, seed = 0\n",
    "\n",
    "def load_images(path_in, path_out, test_size):\n",
    "    images = next(os.walk(path_in))[2] #oswalk is a generator \n",
    "    num_images = len(images)\n",
    "\n",
    "    splitIdx = int(test_size * num_images)\n",
    "    testSize = int((test_size) * num_images)\n",
    "    trainSize = int(math.ceil((1-test_size) * num_images))\n",
    "    \n",
    "    X_train = np.zeros((trainSize,in_height,in_width,color_dim), dtype=np.float32)\n",
    "    X_test = np.zeros((testSize,in_height,in_width,color_dim), dtype=np.float32)\n",
    "    y_train = np.zeros((trainSize,out_height,out_width,color_dim), dtype=np.float32)\n",
    "    y_test  = np.zeros((testSize,out_height,out_width,color_dim), dtype=np.float32)\n",
    "\n",
    "    trainIdx = 0\n",
    "    testIdx = 0\n",
    "    for idx, image in enumerate(images):\n",
    "        image_in_path = os.path.join(path_in,image)\n",
    "        image_out_path = os.path.join(path_out,image)\n",
    "\n",
    "        image_in_raw =  load_img(image_in_path, grayscale=False)\n",
    "        image_out_raw = load_img(image_out_path, grayscale=False)\n",
    "\n",
    "        #converts image to keras preprocessing image, then divide by 255 to un-invert the images\n",
    "        image_in = (img_to_array(image_in_raw)).squeeze() / 255 \n",
    "        image_out = (img_to_array(image_out_raw)).squeeze() / 255          \n",
    " \n",
    "        try:\n",
    "            if (idx % 1000 == 0):\n",
    "                print(\"Stage \" + str(idx))\n",
    "        \n",
    "            if (idx >= splitIdx):\n",
    "                #print(\"trainIdx \" + str(trainIdx))\n",
    "                X_train[trainIdx] = image_in\n",
    "                y_train[trainIdx] = image_out\n",
    "                \n",
    "                trainIdx+=1\n",
    "            else:\n",
    "                #print(\"testIdx \" + str(testIdx))\n",
    "                X_test[testIdx] = image_in\n",
    "                y_test[testIdx] = image_out\n",
    "                \n",
    "                testIdx+=1\n",
    "                \n",
    "        except Exception as e: \n",
    "            print(\"\\nERROR!!!!\")\n",
    "            print(image_in.shape)\n",
    "            print(trainIdx)\n",
    "            \n",
    "            print(image_out.shape)\n",
    "            print(testIdx)\n",
    "            \n",
    "            print(\"id \"+str(idx))\n",
    "            print(image_in_path)\n",
    "            print(e)\n",
    "           \n",
    "            print(\"\\n\")\n",
    "            \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0\n",
      "Stage 1000\n",
      "Stage 2000\n",
      "Stage 3000\n",
      "Stage 4000\n",
      "Stage 5000\n",
      "Stage 6000\n",
      "Stage 7000\n",
      "Stage 8000\n",
      "Stage 9000\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = load_images(path_in, path_out, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Activation\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D,MaxPooling2D,UpSampling2D\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/zeoya/Keras-Super-Resolution/blob/master/myUtils/srcnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#padding output size: see http://cs231n.github.io/convolutional-networks/\n",
    "# output = (Wâˆ’F+2P)/S+1   w- input size, f-kernel size, p-padding size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# the entire SRCNN architecture consists of three CONV =>\\n# RELU layers with *no* zero-padding\\nmodel.add(Conv2D(64, (9, 9), kernel_initializer=\"he_normal\",\\n    input_shape=inputShape))\\nmodel.add(Activation(\"relu\"))\\nmodel.add(Conv2D(32, (1, 1), kernel_initializer=\"he_normal\"))\\nmodel.add(Activation(\"relu\"))\\nmodel.add(Conv2D(depth, (5, 5),\\n    kernel_initializer=\"he_normal\"))\\nmodel.add(Activation(\"relu\"))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# the entire SRCNN architecture consists of three CONV =>\n",
    "# RELU layers with *no* zero-padding\n",
    "model.add(Conv2D(64, (9, 9), kernel_initializer=\"he_normal\",\n",
    "    input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, (1, 1), kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(depth, (5, 5),\n",
    "    kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "inputShape = (in_height, in_width, color_dim)\n",
    "model.add(UpSampling2D((4,4),input_shape=inputShape))\n",
    "#model.add(Conv2D(64, (9, 9), padding='same', kernel_initializer=\"he_normal\")) # 256 X 256 X 64\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, (9, 9), padding='same', kernel_initializer=\"he_normal\")) # 256 X 256 X 32\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(color_dim, (5, 5), padding='same', kernel_initializer=\"he_normal\")) # 256 X 256 X 3\n",
    "model.add(Activation(\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer = RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d_1 (UpSampling2 (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      7808      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 3)       2403      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 10,211\n",
      "Trainable params: 10,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/40\n",
      "8000/8000 [==============================] - 80s 10ms/step - loss: 0.1193 - val_loss: 0.0332\n",
      "Epoch 2/40\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.0300 - val_loss: 0.0169\n",
      "Epoch 3/40\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.0207 - val_loss: 0.0166\n",
      "Epoch 4/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 5/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0144 - val_loss: 0.0133\n",
      "Epoch 6/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0136 - val_loss: 0.0107\n",
      "Epoch 7/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 8/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 9/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0120 - val_loss: 0.0096\n",
      "Epoch 10/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 11/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0111 - val_loss: 0.0167\n",
      "Epoch 12/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 13/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 14/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 15/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 16/40\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 31/40\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.0076 - val_loss: 0.0097\n",
      "Epoch 32/40\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 33/40\n",
      "1280/8000 [===>..........................] - ETA: 46s - loss: 0.0080"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 40\n",
    "\n",
    "trainHistory = model.fit(X_train, y_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = trainHistory.history['loss']\n",
    "val_loss = trainHistory.history['val_loss']\n",
    "epochsRange = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochsRange, loss, label='Training loss',color='g')\n",
    "plt.plot(epochsRange, val_loss, label='Validation loss',color='b')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(256, 256))\n",
    "print(\"Test Images\")\n",
    "\n",
    "for i in range(10):\n",
    "    #plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.show()\n",
    "    plt.imshow(pred[i])\n",
    "    #curr_lbl = y_test[i]\n",
    "    #plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "    plt.show()\n",
    "#plt.figure(figsize=(256, 256))\n",
    "#print(\"Reconstruction of Test Images\")\n",
    "#for i in range(10):\n",
    "    #plt.subplot(2, 10, i+1)\n",
    "    #plt.imshow(pred[i])  \n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
