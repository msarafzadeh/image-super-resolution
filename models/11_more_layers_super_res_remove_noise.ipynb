{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.io import imshow\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7419186022461506335\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11285289370\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7059921121748801549\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#making sure GPU is in use \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "in_height = 64\n",
    "in_width = 64\n",
    "out_height = 256\n",
    "out_width = 256\n",
    "color_dim = 3\n",
    "path_in = '/home/Matthew/image-super-resolution/data/imagenet/10k/res64noisy/'\n",
    "path_out = '/home/Matthew/image-super-resolution/data/imagenet/10k/res256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo: add random shuffle \n",
    "#, seed = 0\n",
    "\n",
    "def load_images(path_in, path_out, test_size):\n",
    "    images = next(os.walk(path_in))[2] #oswalk is a generator \n",
    "    num_images = len(images)\n",
    "\n",
    "    splitIdx = int(test_size * num_images)\n",
    "    testSize = int((test_size) * num_images)\n",
    "    trainSize = int(math.ceil((1-test_size) * num_images))\n",
    "    \n",
    "    X_train = np.zeros((trainSize,in_height,in_width,color_dim), dtype=np.float32)\n",
    "    X_test = np.zeros((testSize,in_height,in_width,color_dim), dtype=np.float32)\n",
    "    y_train = np.zeros((trainSize,out_height,out_width,color_dim), dtype=np.float32)\n",
    "    y_test  = np.zeros((testSize,out_height,out_width,color_dim), dtype=np.float32)\n",
    "\n",
    "    trainIdx = 0\n",
    "    testIdx = 0\n",
    "    for idx, image in enumerate(images):\n",
    "        image_in_path = os.path.join(path_in,image)\n",
    "        image_out_path = os.path.join(path_out,image)\n",
    "\n",
    "        image_in_raw =  load_img(image_in_path, grayscale=False)\n",
    "        image_out_raw = load_img(image_out_path, grayscale=False)\n",
    "\n",
    "        #converts image to keras preprocessing image, then divide by 255 to un-invert the images\n",
    "        image_in = (img_to_array(image_in_raw)).squeeze() / 255 \n",
    "        image_out = (img_to_array(image_out_raw)).squeeze() / 255          \n",
    " \n",
    "        try:\n",
    "            if (idx % 1000 == 0):\n",
    "                print(\"Stage \" + str(idx))\n",
    "        \n",
    "            if (idx >= splitIdx):\n",
    "                #print(\"trainIdx \" + str(trainIdx))\n",
    "                X_train[trainIdx] = image_in\n",
    "                y_train[trainIdx] = image_out\n",
    "                \n",
    "                trainIdx+=1\n",
    "            else:\n",
    "                #print(\"testIdx \" + str(testIdx))\n",
    "                X_test[testIdx] = image_in\n",
    "                y_test[testIdx] = image_out\n",
    "                \n",
    "                testIdx+=1\n",
    "                \n",
    "        except Exception as e: \n",
    "            print(\"\\nERROR!!!!\")\n",
    "            print(image_in.shape)\n",
    "            print(trainIdx)\n",
    "            \n",
    "            print(image_out.shape)\n",
    "            print(testIdx)\n",
    "            \n",
    "            print(\"id \"+str(idx))\n",
    "            print(image_in_path)\n",
    "            print(e)\n",
    "           \n",
    "            print(\"\\n\")\n",
    "            \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0\n",
      "Stage 1000\n",
      "Stage 2000\n",
      "Stage 3000\n",
      "Stage 4000\n",
      "Stage 5000\n",
      "Stage 6000\n",
      "Stage 7000\n",
      "Stage 8000\n",
      "Stage 9000\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = load_images(path_in, path_out, .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Activation\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D,MaxPooling2D,UpSampling2D\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/zeoya/Keras-Super-Resolution/blob/master/myUtils/srcnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#padding output size: see http://cs231n.github.io/convolutional-networks/\n",
    "# output = (Wâˆ’F+2P)/S+1   w- input size, f-kernel size, p-padding size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "inputShape = (in_height, in_width, color_dim)\n",
    "model.add(UpSampling2D((4,4),input_shape=inputShape))\n",
    "model.add(Conv2D(32, (9, 9), padding='same', kernel_initializer=\"he_normal\")) # 256 X 256 X 32\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(16, (7, 7), padding='same', kernel_initializer=\"he_normal\")) # 256 X 256 X 16\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(16, (5, 5), padding='same', kernel_initializer=\"he_normal\")) # 256 X 256 X 16\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(8, (5, 5), padding='same', kernel_initializer=\"he_normal\")) # 256 X 256 X 16\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(color_dim, (5, 5), padding='same', kernel_initializer=\"he_normal\")) # 256 X 256 X 3\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer = RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d_1 (UpSampling2 (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      7808      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 256, 16)      25104     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 16)      6416      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 256, 256, 8)       3208      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256, 256, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 256, 3)       603       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 43,139\n",
      "Trainable params: 43,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/30\n",
      "8000/8000 [==============================] - 171s 21ms/step - loss: 0.0668 - acc: 0.4556 - val_loss: 0.0394 - val_acc: 0.5179\n",
      "Epoch 2/30\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 30\n",
    "\n",
    "trainHistory = model.fit(X_train, y_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = trainHistory.history['loss']\n",
    "val_loss = trainHistory.history['val_loss']\n",
    "epochsRange = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochsRange, loss, label='Training loss',color='g')\n",
    "plt.plot(epochsRange, val_loss, label='Validation loss',color='b')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(trainHistory.history['acc'])\n",
    "plt.plot(trainHistory.history['val_acc'])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(trainHistory.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(256, 256))\n",
    "print(\"Test Images\")\n",
    "\n",
    "for i in range(10):\n",
    "    #plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.show()\n",
    "    plt.imshow(pred[i])\n",
    "    #curr_lbl = y_test[i]\n",
    "    #plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "    plt.show()\n",
    "#plt.figure(figsize=(256, 256))\n",
    "#print(\"Reconstruction of Test Images\")\n",
    "#for i in range(10):\n",
    "    #plt.subplot(2, 10, i+1)\n",
    "    #plt.imshow(pred[i])  \n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(pred[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
